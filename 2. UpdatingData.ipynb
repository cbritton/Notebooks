{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d01d183-96e1-4d28-b0bf-7dbd63050220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import arrow\n",
    "import finnhub\n",
    "from limit import limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17894341-c84c-45a2-8478-6a4a89b774c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"./data/daily\"\n",
    "finnhub_api_key = \"............\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50543d75-2f13-4d93-a219-de8c8798f355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 3)\n",
      "┌────────┬─────────────────────┬─────────────────────┐\n",
      "│ Symbol ┆ First Date          ┆ Last Date           │\n",
      "│ ---    ┆ ---                 ┆ ---                 │\n",
      "│ str    ┆ datetime[ns]        ┆ datetime[ns]        │\n",
      "╞════════╪═════════════════════╪═════════════════════╡\n",
      "│ SNOW   ┆ 2020-09-16 00:00:00 ┆ 2023-08-10 20:00:00 │\n",
      "│ TLT    ┆ 2010-01-04 00:00:00 ┆ 2023-08-10 20:00:00 │\n",
      "│ AMD    ┆ 2010-01-04 00:00:00 ┆ 2023-08-10 20:00:00 │\n",
      "└────────┴─────────────────────┴─────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "df = (pl.scan_parquet(f\"{data_directory}/*.parquet\")\n",
    "    .groupby(\"Symbol\")\n",
    "    .agg(\n",
    "        pl.col(\"Date\").min().alias(\"First Date\"),\n",
    "        pl.col(\"Date\").max().alias(\"Last Date\")\n",
    "    )\n",
    "    .collect()\n",
    ")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c180c956-94c4-4ae5-955c-9b0eeb1b5831",
   "metadata": {},
   "outputs": [],
   "source": [
    "@limit(60,60)\n",
    "def fetch_finnhub(symbol:str, starttime:arrow, endtime:arrow, finnhub_api_key:str, interval:str='D') -> dict:\n",
    "    finnhub_client = finnhub.Client(api_key=finnhub_api_key)\n",
    "    content = finnhub_client.stock_candles(\n",
    "        symbol,\n",
    "        interval,\n",
    "        int(starttime.datetime.timestamp()),\n",
    "        int(endtime.datetime.timestamp())\n",
    "    )\n",
    "    if 'no_data' in content.values():\n",
    "        return None\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f643c538-4860-471f-ba58-d28ab77fb901",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_finnhub_to_polars(symbol:str, content:dict)-> pl.DataFrame:\n",
    "    df = (pl.from_dict(content)\n",
    "        .with_columns([\n",
    "            # finnhub timestamps are in unix time (seconds) in GMT so \n",
    "            # we have to replace the timezone, convert to ET and then remove it\n",
    "            pl.from_epoch(\"t\")\n",
    "                .dt.replace_time_zone(\"GMT\")\n",
    "                .dt.convert_time_zone(\"US/Eastern\")\n",
    "                .dt.replace_time_zone(None)\n",
    "                # we'll have to change this to use pl.Date but since the data\n",
    "                # have is already using Datetime[ns] we'll stick with this\n",
    "                .cast(pl.Datetime).dt.cast_time_unit(\"ns\")\n",
    "                .alias(\"Date\"),\n",
    "\n",
    "            # add the symbol as a column for easier grouping\n",
    "            pl.lit(symbol).alias(\"Symbol\"),\n",
    "\n",
    "            # cast the types to ensure all of the data is homogenous and change the names\n",
    "            pl.col(\"v\").cast(pl.Int64).alias(\"Volume\"),\n",
    "            pl.col(\"c\").cast(pl.Float64).alias(\"Close\"),\n",
    "            # finnhub doen not have an adjusted close like yahoo so we'll\n",
    "            #  have to substitute it with the close\n",
    "            pl.col(\"c\").cast(pl.Float64).alias(\"Adj Close\"),\n",
    "            pl.col(\"h\").cast(pl.Float64).alias(\"High\"),\n",
    "            pl.col(\"l\").cast(pl.Float64).alias(\"Low\"),\n",
    "            pl.col(\"o\").cast(pl.Float64).alias(\"Open\"),\n",
    "        ])\n",
    "        .select([\n",
    "            pl.col('Date'),\n",
    "            pl.col('Open'),\n",
    "            pl.col('High'),\n",
    "            pl.col('Low'),\n",
    "            pl.col('Close'),\n",
    "            pl.col('Adj Close'),\n",
    "            pl.col('Volume'),\n",
    "            pl.col('Symbol')\n",
    "        ])\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a32b008-5255-4790-939f-5e49e8c3f96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_save(df:pl.DataFrame, filename:str) -> None:\n",
    "    '''\n",
    "    Merge the dataframe with the historicals.\n",
    "    '''\n",
    "    (pl\n",
    "        .read_parquet(filename)\n",
    "        # use vstack to append the latest data\n",
    "        .vstack(df)\n",
    "        # if there happens to be an overlap with the data, the use the\n",
    "        #    unique function and keep the most recent\n",
    "        .unique(subset='Date', keep='last')\n",
    "        # write everthing out\n",
    "        .write_parquet(filename)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf4d6d50-49ac-43d7-9e20-6a1460fddcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the data from for what we currently have on disk\n",
    "for item in df.iter_rows(named=True):\n",
    "    # get the symbol since we'll need that for the finnhum request\n",
    "    symbol = item.get(\"Symbol\")\n",
    "    \n",
    "    # get the last date of the data\n",
    "    last_date = arrow.get(item.get(\"Last Date\"))\n",
    "    # fetch the raw content from finnhub. Notice that we use the now()\n",
    "    # function from arrow to get today's date.\n",
    "    data = fetch_finnhub(symbol, last_date, arrow.now(), finnhub_api_key)\n",
    "    # convert the response to a polars dataframe\n",
    "    df_convert = convert_finnhub_to_polars(symbol, data)\n",
    "    # merge and save the data\n",
    "    merge_and_save(df_convert, f\"{data_directory}/{symbol}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c546cf64-f7d3-492b-8ea0-5affd89dcb7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
